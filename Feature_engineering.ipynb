{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature engineering.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNeTEiW+W9ubpm96GhmV91R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StavroK/MtySaturdayAI2020/blob/master/Feature_engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxX2qY1Fc1Lc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_train_instances = \"train_stances.csv\"\n",
        "file_train_bodies = \"train_bodies.csv\"\n",
        "file_test_instances = \"test_stances_unlabeled.csv\"\n",
        "file_test_bodies = \"test_bodies.csv\"\n",
        "file_predictions = 'predictions_test.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYkPVgciEqOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_ref = {'agree': 0, 'disagree': 1, 'discuss': 2, 'unrelated': 3}\n",
        "label_ref_rev = {0: 'agree', 1: 'disagree', 2: 'discuss', 3: 'unrelated'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkvCLb63FZcP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = list(stopwords.words('english'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyeRAdfPGWWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ModelData:\n",
        "\n",
        "    def __init__(self, file_instances, file_bodies):\n",
        "\n",
        "        # Load data\n",
        "        self.instances = self.read(file_instances)\n",
        "        bodies = self.read(file_bodies)\n",
        "        self.heads = {}\n",
        "        self.bodies = {}\n",
        "\n",
        "        # Process instances\n",
        "        for instance in self.instances:\n",
        "            if instance['Headline'] not in self.heads:\n",
        "                head_id = len(self.heads)\n",
        "                self.heads[instance['Headline']] = head_id\n",
        "            instance['Body ID'] = int(instance['Body ID'])\n",
        "\n",
        "        # Process bodies\n",
        "        for body in bodies:\n",
        "            self.bodies[int(body['Body ID'])] = body['articleBody']\n",
        "\n",
        "    def read(self, filename):\n",
        "\n",
        "        # Initialise\n",
        "        rows = []\n",
        "\n",
        "        # Process file\n",
        "        with open(filename, \"r\", encoding='utf-8') as table:\n",
        "            r = DictReader(table)\n",
        "            for line in r:\n",
        "                rows.append(line)\n",
        "\n",
        "        return rows\n",
        "\n",
        "\n",
        "# Define relevant functions\n",
        "def pipeline_train(train, test, lim_unigram):\n",
        "\n",
        "    # Initialise\n",
        "    heads = []\n",
        "    heads_track = {}\n",
        "    bodies = []\n",
        "    bodies_track = {}\n",
        "    body_ids = []\n",
        "    id_ref = {}\n",
        "    train_set = []\n",
        "    train_stances = []\n",
        "    cos_track = {}\n",
        "    test_heads = []\n",
        "    test_heads_track = {}\n",
        "    test_bodies = []\n",
        "    test_bodies_track = {}\n",
        "    test_body_ids = []\n",
        "    head_tfidf_track = {}\n",
        "    body_tfidf_track = {}\n",
        "\n",
        "    # Identify unique heads and bodies\n",
        "    for instance in train.instances:\n",
        "        head = instance['Headline']\n",
        "        body_id = instance['Body ID']\n",
        "        if head not in heads_track:\n",
        "            heads.append(head)\n",
        "            heads_track[head] = 1\n",
        "        if body_id not in bodies_track:\n",
        "            bodies.append(train.bodies[body_id])\n",
        "            bodies_track[body_id] = 1\n",
        "            body_ids.append(body_id)\n",
        "\n",
        "    for instance in test.instances:\n",
        "        head = instance['Headline']\n",
        "        body_id = instance['Body ID']\n",
        "        if head not in test_heads_track:\n",
        "            test_heads.append(head)\n",
        "            test_heads_track[head] = 1\n",
        "        if body_id not in test_bodies_track:\n",
        "            test_bodies.append(test.bodies[body_id])\n",
        "            test_bodies_track[body_id] = 1\n",
        "            test_body_ids.append(body_id)\n",
        "\n",
        "    # Create reference dictionary\n",
        "    for i, elem in enumerate(heads + body_ids):\n",
        "        id_ref[elem] = i\n",
        "\n",
        "    # Create vectorizers and BOW and TF arrays for train set\n",
        "    bow_vectorizer = CountVectorizer(max_features=lim_unigram, stop_words=stop_words)\n",
        "    bow = bow_vectorizer.fit_transform(heads + bodies)  # Train set only\n",
        "\n",
        "    tfreq_vectorizer = TfidfTransformer(use_idf=False).fit(bow)\n",
        "    tfreq = tfreq_vectorizer.transform(bow).toarray()  # Train set only\n",
        "\n",
        "    tfidf_vectorizer = TfidfVectorizer(max_features=lim_unigram, stop_words=stop_words).\\\n",
        "        fit(heads + bodies + test_heads + test_bodies)  # Train and test sets\n",
        "\n",
        "    # Process train set\n",
        "    for instance in train.instances:\n",
        "        head = instance['Headline']\n",
        "        body_id = instance['Body ID']\n",
        "        head_tf = tfreq[id_ref[head]].reshape(1, -1)\n",
        "        body_tf = tfreq[id_ref[body_id]].reshape(1, -1)\n",
        "        if head not in head_tfidf_track:\n",
        "            head_tfidf = tfidf_vectorizer.transform([head]).toarray()\n",
        "            head_tfidf_track[head] = head_tfidf\n",
        "        else:\n",
        "            head_tfidf = head_tfidf_track[head]\n",
        "        if body_id not in body_tfidf_track:\n",
        "            body_tfidf = tfidf_vectorizer.transform([train.bodies[body_id]]).toarray()\n",
        "            body_tfidf_track[body_id] = body_tfidf\n",
        "        else:\n",
        "            body_tfidf = body_tfidf_track[body_id]\n",
        "        if (head, body_id) not in cos_track:\n",
        "            tfidf_cos = cosine_similarity(head_tfidf, body_tfidf)[0].reshape(1, 1)\n",
        "            cos_track[(head, body_id)] = tfidf_cos\n",
        "        else:\n",
        "            tfidf_cos = cos_track[(head, body_id)]\n",
        "        feat_vec = np.squeeze(np.c_[head_tf, body_tf, tfidf_cos])\n",
        "        train_set.append(feat_vec)\n",
        "        train_stances.append(label_ref[instance['Stance']])\n",
        "\n",
        "    return train_set, train_stances, bow_vectorizer, tfreq_vectorizer, tfidf_vectorizer\n",
        "\n",
        "\n",
        "def pipeline_test(test, bow_vectorizer, tfreq_vectorizer, tfidf_vectorizer):\n",
        "\n",
        "    # Initialise\n",
        "    test_set = []\n",
        "    heads_track = {}\n",
        "    bodies_track = {}\n",
        "    cos_track = {}\n",
        "\n",
        "    # Process test set\n",
        "    for instance in test.instances:\n",
        "        head = instance['Headline']\n",
        "        body_id = instance['Body ID']\n",
        "        if head not in heads_track:\n",
        "            head_bow = bow_vectorizer.transform([head]).toarray()\n",
        "            head_tf = tfreq_vectorizer.transform(head_bow).toarray()[0].reshape(1, -1)\n",
        "            head_tfidf = tfidf_vectorizer.transform([head]).toarray().reshape(1, -1)\n",
        "            heads_track[head] = (head_tf, head_tfidf)\n",
        "        else:\n",
        "            head_tf = heads_track[head][0]\n",
        "            head_tfidf = heads_track[head][1]\n",
        "        if body_id not in bodies_track:\n",
        "            body_bow = bow_vectorizer.transform([test.bodies[body_id]]).toarray()\n",
        "            body_tf = tfreq_vectorizer.transform(body_bow).toarray()[0].reshape(1, -1)\n",
        "            body_tfidf = tfidf_vectorizer.transform([test.bodies[body_id]]).toarray().reshape(1, -1)\n",
        "            bodies_track[body_id] = (body_tf, body_tfidf)\n",
        "        else:\n",
        "            body_tf = bodies_track[body_id][0]\n",
        "            body_tfidf = bodies_track[body_id][1]\n",
        "        if (head, body_id) not in cos_track:\n",
        "            tfidf_cos = cosine_similarity(head_tfidf, body_tfidf)[0].reshape(1, 1)\n",
        "            cos_track[(head, body_id)] = tfidf_cos\n",
        "        else:\n",
        "            tfidf_cos = cos_track[(head, body_id)]\n",
        "        feat_vec = np.squeeze(np.c_[head_tf, body_tf, tfidf_cos])\n",
        "        test_set.append(feat_vec)\n",
        "\n",
        "    return test_set\n",
        "\n",
        "\n",
        "def load_model(sess):\n",
        "\n",
        "    saver = tf.train.Saver()\n",
        "    saver.restore(sess, './model/model.checkpoint')\n",
        "\n",
        "\n",
        "def save_predictions(pred, file):\n",
        "\n",
        "    with open(file, 'w') as csvfile:\n",
        "        fieldnames = ['Stance']\n",
        "        writer = DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "        writer.writeheader()\n",
        "        for instance in pred:\n",
        "            writer.writerow({'Stance': label_ref_rev[instance]})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1ZntwLOvMfk",
        "colab_type": "code",
        "outputId": "63e6f06d-9d5f-4f0e-80f3-e35cbee03982",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "%cd /usr/local/lib/python3.6/dist-packages\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as mtick\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import pandas as pd\n",
        "import pickle as pkl\n",
        "import re\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import chi2\n",
        "import warnings\n",
        "from csv import DictReader\n",
        "from csv import DictWriter\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from util import *\n",
        "import random\n",
        "import pickle\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from pprint import pprint\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GqsZiiBguQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataframe\n",
        "path_df = \"/home/lnc/0. Latest News Classifier/03. Feature Engineering/Pickles/df.pickle\"\n",
        "with open(path_df, 'rb') as data:\n",
        "    df = pickle.load(data)\n",
        "\n",
        "# features_train\n",
        "path_features_train = \"/home/lnc/0. Latest News Classifier/03. Feature Engineering/Pickles/features_train.pickle\"\n",
        "with open(path_features_train, 'rb') as data:\n",
        "    features_train = pickle.load(data)\n",
        "\n",
        "# labels_train\n",
        "path_labels_train = \"/home/lnc/0. Latest News Classifier/03. Feature Engineering/Pickles/labels_train.pickle\"\n",
        "with open(path_labels_train, 'rb') as data:\n",
        "    labels_train = pickle.load(data)\n",
        "\n",
        "# features_test\n",
        "path_features_test = \"/home/lnc/0. Latest News Classifier/03. Feature Engineering/Pickles/features_test.pickle\"\n",
        "with open(path_features_test, 'rb') as data:\n",
        "    features_test = pickle.load(data)\n",
        "\n",
        "# labels_test\n",
        "path_labels_test = \"/home/lnc/0. Latest News Classifier/03. Feature Engineering/Pickles/labels_test.pickle\"\n",
        "with open(path_labels_test, 'rb') as data:\n",
        "    labels_test = pickle.load(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpkeY_ZMgx8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(features_train.shape)\n",
        "print(features_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRmk9gZgfgB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_0 = LogisticRegression(random_state = 8)\n",
        "\n",
        "print('Parameters currently in use:\\n')\n",
        "pprint(lr_0.get_params())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5Qa1D_BfjDx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# C\n",
        "C = [float(x) for x in np.linspace(start = 0.1, stop = 1, num = 10)]\n",
        "\n",
        "# multi_class\n",
        "multi_class = ['multinomial']\n",
        "\n",
        "# solver\n",
        "solver = ['newton-cg', 'sag', 'saga', 'lbfgs']\n",
        " \n",
        "# class_weight\n",
        "class_weight = ['balanced', None]\n",
        "\n",
        "# penalty\n",
        "penalty = ['l2']\n",
        "\n",
        "# Create the random grid\n",
        "random_grid = {'C': C,\n",
        "               'multi_class': multi_class,\n",
        "               'solver': solver,\n",
        "               'class_weight': class_weight,\n",
        "               'penalty': penalty}\n",
        "\n",
        "pprint(random_grid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1h_oYIpfrmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First create the base model to tune\n",
        "lrc = LogisticRegression(random_state=8)\n",
        "\n",
        "# Definition of the random search\n",
        "random_search = RandomizedSearchCV(estimator=lrc,\n",
        "                                   param_distributions=random_grid,\n",
        "                                   n_iter=50,\n",
        "                                   scoring='accuracy',\n",
        "                                   cv=3, \n",
        "                                   verbose=1, \n",
        "                                   random_state=8)\n",
        "\n",
        "# Fit the random search model\n",
        "random_search.fit(features_train, labels_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ3eYBcxfwvN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"The best hyperparameters from Random Search are:\")\n",
        "print(random_search.best_params_)\n",
        "print(\"\")\n",
        "print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
        "print(random_search.best_score_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvgXogtOfz2Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the parameter grid based on the results of random search \n",
        "C = [float(x) for x in np.linspace(start = 0.6, stop = 1, num = 10)]\n",
        "multi_class = ['multinomial']\n",
        "solver = ['sag']\n",
        "class_weight = ['balanced']\n",
        "penalty = ['l2']\n",
        "\n",
        "param_grid = {'C': C,\n",
        "               'multi_class': multi_class,\n",
        "               'solver': solver,\n",
        "               'class_weight': class_weight,\n",
        "               'penalty': penalty}\n",
        "\n",
        "# Create a base model\n",
        "lrc = LogisticRegression(random_state=8)\n",
        "\n",
        "# Manually create the splits in CV in order to be able to fix a random_state (GridSearchCV doesn't have that argument)\n",
        "cv_sets = ShuffleSplit(n_splits = 3, test_size = .33, random_state = 8)\n",
        "\n",
        "# Instantiate the grid search model\n",
        "grid_search = GridSearchCV(estimator=lrc, \n",
        "                           param_grid=param_grid,\n",
        "                           scoring='accuracy',\n",
        "                           cv=cv_sets,\n",
        "                           verbose=1)\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(features_train, labels_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDwMB3zCf8C6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"The best hyperparameters from Grid Search are:\")\n",
        "print(grid_search.best_params_)\n",
        "print(\"\")\n",
        "print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
        "print(grid_search.best_score_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_25q0bFf8tq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_lrc = grid_search.best_estimator_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vK5cdH8Jf_xq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_lrc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hC2H4Z3qgBhx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_lrc.fit(features_train, labels_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v65cUYsigETE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lrc_pred = best_lrc.predict(features_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcfmbH7NgGTt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training accuracy\n",
        "print(\"The training accuracy is: \")\n",
        "print(accuracy_score(labels_train, best_lrc.predict(features_train)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfN-fKYdgJb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test accuracy\n",
        "print(\"The test accuracy is: \")\n",
        "print(accuracy_score(labels_test, lrc_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRTPYX-mgP0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Classification report\n",
        "print(\"Classification report\")\n",
        "print(classification_report(labels_test,lrc_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjNAupfEgUiz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aux_df = df[['Category', 'Category_Code']].drop_duplicates().sort_values('Category_Code')\n",
        "conf_matrix = confusion_matrix(labels_test, lrc_pred)\n",
        "plt.figure(figsize=(12.8,6))\n",
        "sns.heatmap(conf_matrix, \n",
        "            annot=True,\n",
        "            xticklabels=aux_df['Category'].values, \n",
        "            yticklabels=aux_df['Category'].values,\n",
        "            cmap=\"Blues\")\n",
        "plt.ylabel('Predicted')\n",
        "plt.xlabel('Actual')\n",
        "plt.title('Confusion matrix')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZHmmaqDgVgZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = LogisticRegression(random_state = 8)\n",
        "base_model.fit(features_train, labels_train)\n",
        "accuracy_score(labels_test, base_model.predict(features_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NCoSykegZkY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_lrc.fit(features_train, labels_train)\n",
        "accuracy_score(labels_test, best_lrc.predict(features_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KPz9nNTgbu_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = {\n",
        "     'Model': 'Logistic Regression',\n",
        "     'Training Set Accuracy': accuracy_score(labels_train, best_lrc.predict(features_train)),\n",
        "     'Test Set Accuracy': accuracy_score(labels_test, lrc_pred)\n",
        "}\n",
        "\n",
        "df_models_lrc = pd.DataFrame(d, index=[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQqLHiE5gfSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_models_lrc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTkRL3togidG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('Models/best_lrc.pickle', 'wb') as output:\n",
        "    pickle.dump(best_lrc, output)\n",
        "    \n",
        "with open('Models/df_models_lrc.pickle', 'wb') as output:\n",
        "    pickle.dump(df_models_lrc, output)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}